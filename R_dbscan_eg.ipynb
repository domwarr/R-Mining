{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Density-based Spatial Clustering of Applications with Noise (DBSCAN) in R\n",
    "This notebook is designed to help get you familiar with using the DBSCAN algorithm in R through a simple exercise.  \n",
    "\n",
    "In this notebook, we will load and explore 'seeds.txt' in R, which is a dataset containing measurements of geometrical properties of kernels belonging to three different varieties of wheat. ",
    "Specifically, this exercise covers:\n",
    "\n",
    "1. Installing and loading the DBSCAN library and the data in R\n",
    "2. Creating a subset from the datatset\n",
    "3. Using the dbscan function to obtain clusters\n",
    "4. Convert the clusters to factors \n",
    "5. Attaching the clusters to the measurements\n",
    "6. Visualizing the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and loading the DBSCAN library and the data in R\n",
    "We begin by installing the dbscan package and loading it along with the dataset .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#installing the library 'dbscan'\n",
    "install.packages(\"dbscan\", dependencies = TRUE)\n",
    "library('dbscan')\n",
    "#Downloading the file in the Data Scientist Workbench\n",
    "download.file(\"https://ibm.box.com/shared/static/th5dsj5txtw052dt2k9i5hekkjhydda2.csv\",\"/resources/seeds.csv\")",
    "head(seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the dbscan function to obtain clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching the clusters to the measurements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data\n",
    "Filter the DataFrame to only retain rows with `mpg` less than 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SparkR::head(SparkR::filter(sdf, sdf$mpg < 18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operating on Columns\n",
    "SparkR also provides a number of functions that can directly applied to columns for data processing and aggregation. The example below shows the use of basic arithmetic functions to convert lb to metric ton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf$wtTon <- sdf$wt * 0.45\n",
    "SparkR::head(sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping, Aggregation\n",
    "SparkR data frames support a number of commonly used functions to aggregate data after grouping. For example we can compute the average weight of cars by their cylinders as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SparkR::head(summarize(groupBy(sdf, sdf$cyl), wtavg = avg(sdf$wtTon)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can also sort the output from the aggregation to get the most common cars\n",
    "car_counts <-summarize(groupBy(sdf, sdf$cyl), count = n(sdf$wtTon))\n",
    "SparkR::head(arrange(car_counts, desc(car_counts$count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running SQL Queries from Spark DataFrames\n",
    "A Spark DataFrame can also be registered as a temporary table in Spark SQL and registering a DataFrame as a table allows you to run SQL queries over its data. The `sql` function enables applications to run SQL queries programmatically and returns the result as a DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Register this DataFrame as a table.\n",
    "registerTempTable(sdf, \"cars\")\n",
    "# SQL statements can be run by using the sql method\n",
    "highgearcars <- sql(sqlContext, \"SELECT gear FROM cars WHERE cyl >= 4 AND cyl <= 9\")\n",
    "SparkR::head(highgearcars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "NOTE: This tutorial draws heavily from the original \n",
    "[Spark Quick Start Guide](http://spark.apache.org/docs/latest/quick-start.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free courses on [Big Data University](https://bigdatauniversity.com/courses/analyzing-big-data-r-using-apache-spark/?utm_source=tutorial-spark-r&utm_medium=dswb&utm_campaign=bdu):\n",
    "\n",
    "<a href=\"https://bigdatauniversity.com/courses/analyzing-big-data-r-using-apache-spark/?utm_source=tutorial-spark-r&utm_medium=dswb&utm_campaign=bdu\"><img src = \"https://ibm.box.com/shared/static/14f58d6iazn71i794oqsdlaimp9k51xq.png\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Authors:</h3>\n",
    "<br>\n",
    "<a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">\n",
    "    <div class=\"teacher-image\" style=\"    float: left;\n",
    "        width: 115px;\n",
    "        height: 115px;\n",
    "        margin-right: 10px;\n",
    "        margin-bottom: 10px;\n",
    "        border: 1px solid #CCC;\n",
    "        padding: 3px;\n",
    "        border-radius: 3px;\n",
    "        text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\"/>\n",
    "    </div>\n",
    "</a>\n",
    "\n",
    "<h4>Saeed Aghabozorgi</h4>\n",
    "<p><a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>, PhD is a Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clients’ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<a href=\"https://ca.linkedin.com/in/polonglin\">\n",
    "    <div class=\"teacher-image\" style=\"    float: left;\n",
    "        width: 115px;\n",
    "        height: 115px;\n",
    "        margin-right: 10px;\n",
    "        margin-bottom: 10px;\n",
    "        border: 1px solid #CCC;\n",
    "        padding: 3px;\n",
    "        border-radius: 3px;\n",
    "        text-align: center;\"><img class=\"alignnone size-medium wp-image-2177\" src=\"https://ibm.box.com/shared/static/2ygdi03ahcr97df2ofrr6cf8knq4kodd.jpg\" alt=\"Polong Lin\" width=\"300\" height=\"300\"/>\n",
    "    </div>\n",
    "</a>\n",
    "<h4>Polong Lin</h4>\n",
    "<p>\n",
    "<a href=\"https://ca.linkedin.com/in/polonglin\">Polong Lin</a> is a Data Scientist at IBM in Canada. Under the Emerging Technologies division, Polong is responsible for educating the next generation of data scientists through Big Data University. Polong is a regular speaker in conferences and meetups, and holds a M.Sc. in Cognitive Psychology.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; 2016 [Big Data University](https://bigdatauniversity.com/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).​"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
